{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "128dd280",
   "metadata": {},
   "source": [
    "# Table of Contents\n",
    "\n",
    "This notebook contains the following: \n",
    "\n",
    "* Importing libraries \n",
    "* Turning project path into a string\n",
    "* Importing data sets \n",
    "* Data Consistency Checks (identification and treatment) \n",
    "    * Mixed Type Data \n",
    "    * Missing Values \n",
    "    * Duplicates \n",
    "* Exporting Dataset \n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6796b4e6",
   "metadata": {},
   "source": [
    "# Step 1 - Consistency Checks from Exercise"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3345146c",
   "metadata": {},
   "source": [
    "# 01. Importing libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "d8f23335",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import libraries\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "91bd334a",
   "metadata": {},
   "source": [
    "# 02. Turning project path into a string"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "cdd7b06e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/Users/aysha/Documents/Instacart Basket Analysis/'"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Turn project folder path into a string\n",
    "'/Users/aysha/Documents/Instacart Basket Analysis/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "9efb843c",
   "metadata": {},
   "outputs": [],
   "source": [
    "path = r'/Users/aysha/Documents/Instacart Basket Analysis/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "6c1468bb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/Users/aysha/Documents/Instacart Basket Analysis/'"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "path"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c1efdb86",
   "metadata": {},
   "source": [
    "# 03. Importing data sets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "6f4534d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import the “products.csv” file into Jupyter as df_prods\n",
    "df_prods = pd.read_csv(os.path.join(path, '02 Data', 'Original Data', 'products.csv'), index_col = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "592760e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import the orders_wrangled.csv from 'Prepared Data' folder as dfords\n",
    "dfords = pd.read_csv(os.path.join(path, '02 Data', 'Prepared Data', 'orders_wrangled.csv'), index_col = False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1c7033ab",
   "metadata": {},
   "source": [
    "# 04. Data Consistency Checks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4b80100d",
   "metadata": {},
   "outputs": [],
   "source": [
    "dfords.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9f495779",
   "metadata": {},
   "source": [
    "# 05. Checking for Mixed-Type Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "a83c46c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Create a dataframe\n",
    "df_test = pd.DataFrame()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "816140b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a mixed type column\n",
    "df_test['mix'] = ['a', 'b', 1, True]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "880d2637",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check first 5 rows\n",
    "df_test.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "af89df90",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mix\n"
     ]
    }
   ],
   "source": [
    "# Check for mixed type data\n",
    "for col in df_test.columns.tolist():\n",
    "  weird = (df_test[[col]].applymap(type) != df_test[[col]].iloc[0].apply(type)).any(axis = 1)\n",
    "  if len (df_test[weird]) > 0:\n",
    "    print (col)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "22f193b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fix the mixed type data (by converting numeric values to string)\n",
    "df_test['mix'] = df_test['mix'].astype('str')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2b5c10e8",
   "metadata": {},
   "source": [
    "# 06. Missing Values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "62235d64",
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "product_id        0\n",
       "product_name     16\n",
       "aisle_id          0\n",
       "department_id     0\n",
       "prices            0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Finding missing values in df_prods\n",
    "df_prods.isnull().sum()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "e1f9a47b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creating a subset of the dataframe containing only the missing values in question\n",
    "df_nan = df_prods[df_prods['product_name'].isnull() == True]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4447edf8",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_nan"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "530518f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fill in missing values by imputing the value with mean or median( if missing values are numeric)\n",
    "\n",
    "#df['column with missings'].fillna(mean value, inplace=True)\n",
    "\n",
    "#df['column with missings'].fillna(median value, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "e32291b6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(49693, 5)"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Find number of rows and columns in dataframe\n",
    "df_prods.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "98f6dd74",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a new dataframe df_prods_clean to remove missing values \n",
    "df_prods_clean = df_prods[df_prods['product_name'].isnull() == False]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8ae9074b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Find number of rows and columns in the newly created dataframe\n",
    "df_prods_clean.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "82579eac",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Another way for dropping missing data\n",
    "#df_prods.dropna(inplace = True)\n",
    "#If you wanted to use this command to drop only the NaNs from a particular column, the code would look like this:\n",
    "#df_prods.dropna(subset = [‘product_name’, inplace = True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4ba3b8e1",
   "metadata": {},
   "source": [
    "# 07. Duplicates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "3c17e2f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Finding duplicates\n",
    "df_dups = df_prods_clean[df_prods_clean.duplicated()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c4a98d91",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_dups"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "63b0f8aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Addressing duplicates\n",
    "# First check the number of rows and columns in the dataframe\n",
    "df_prods_clean.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "df5f6712",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Addressing duplicates \n",
    "# Dropping duplicates\n",
    "# Create a new dataframe that doesn’t include the duplicates you just identified using the drop_duplicates() function:\n",
    "df_prods_clean_no_dups = df_prods_clean.drop_duplicates()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fc4bf8ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check number of rows and columns of new dataframe\n",
    "df_prods_clean_no_dups.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "33bd11b9",
   "metadata": {},
   "source": [
    "# 08. Exporting Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "f30bea1e",
   "metadata": {},
   "outputs": [],
   "source": [
    "#df_prods_clean_no_dups.to_csv(os.path.join(path, '02 Data','Prepared Data', 'products_checked.csv'))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4159dafa",
   "metadata": {},
   "source": [
    "\n",
    "# Step 2 \n",
    "\n",
    "# Run the df.describe() function on your df_prods dataframe. Using your new knowledge about how to interpret the output of this function, share in a markdown cell whether anything about the data looks off or should be investigated further.\n",
    "\n",
    "# Tip: Keep an eye on min and max values!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "597a34e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Running the describe function for statistical values\n",
    "df_prods.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f3480f2c",
   "metadata": {},
   "source": [
    "### The maximum price seems to be entered incorrectly as it seems to be quite high especially for goods sold by an online grocery company.  "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "52fb6dd2",
   "metadata": {},
   "source": [
    "# Step 3 \n",
    "\n",
    "# Check for mixed-type data in your df_ords dataframe."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "d5863f58",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check for mixed type data in dfords dataframe\n",
    "for col in dfords.columns.tolist():\n",
    "  weird = (dfords[[col]].applymap(type) != dfords[[col]].iloc[0].apply(type)).any(axis = 1)\n",
    "  if len (dfords[weird]) > 0:\n",
    "    print (col)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9b42a129",
   "metadata": {},
   "source": [
    "### There is no mixed data type in the dfords dataframe"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dd3cf5fd",
   "metadata": {},
   "source": [
    "# Step 4 \n",
    "\n",
    "# If you find mixed-type data, fix it. The column in question should contain observations of a single data type."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f1f3a613",
   "metadata": {},
   "source": [
    "### There is no mixed data type hence there's no need of fixing here."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1a8ff2b6",
   "metadata": {},
   "source": [
    "# Step 5 \n",
    "\n",
    "# Run a check for missing values in your df_ords dataframe. In a markdown cell, report your findings and propose an explanation for any missing values you find.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "1772b0f5",
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Unnamed: 0                     0\n",
       "order_id                       0\n",
       "user_id                        0\n",
       "order_number                   0\n",
       "orders_day_of_week             0\n",
       "order_time_of_day              0\n",
       "days_since_prior_order    206209\n",
       "dtype: int64"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Finding missing values in dfords\n",
    "dfords.isnull().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2dfa657d",
   "metadata": {},
   "source": [
    "### The column 'days_since_prior_order' has a lot of missing values. This could be mainly due to the reason that there are first time customers hence have no purchase history in Instacart's database. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "432ba986",
   "metadata": {},
   "source": [
    "# Step 6 \n",
    "\n",
    "# Address the missing values using an appropriate method. In a markdown cell, explain why you used your method of choice.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "572684e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creating a subset of the dataframe containing only the missing values in question\n",
    "dfords_nan = dfords[dfords['days_since_prior_order'].isnull() == True]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9ac7a1ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "dfords_nan"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5eeb45ef",
   "metadata": {},
   "source": [
    "### The approach I would take is to create a new variable that acts like a flag based on the missing value. So this I would do by creating a new column under the heading 'first_time_customers' and defining the output as true and false depending on the column of 'days_since_prior_order'. \n",
    "\n",
    "### Imputing values by the mean and median wouldn't make sense here as this column indicates customers with no prior purchase history. \n",
    "\n",
    "### The method of creating a new dataframe with a new column is as follows:  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "1f684f5e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a new dataframe and set a new column for first time customers\n",
    "dfords_clean = dfords"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "47ec0f96",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Adding a column of 'first_time_customers' depending on the value from the column 'days_since_prior_order'\n",
    "dfords_clean['first_time_customers'] = dfords['days_since_prior_order'].isnull() == True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "430e3ce6",
   "metadata": {},
   "outputs": [],
   "source": [
    "dfords_clean"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3139a4ce",
   "metadata": {},
   "source": [
    "# Step 7 \n",
    "\n",
    "# Run a check for duplicate values in your df_ords data. In a markdown cell, report your findings and propose an explanation for any duplicate values you find.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "36a79dfb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Finding duplicates in the dfords dataframe\n",
    "dfords_dups = dfords_clean[dfords_clean.duplicated()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8c592efd",
   "metadata": {},
   "outputs": [],
   "source": [
    "dfords_dups"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "af59d342",
   "metadata": {},
   "source": [
    "### There are no duplicates in the dfords_clean dataframe"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "468e66fd",
   "metadata": {},
   "source": [
    "# Step 8 \n",
    "\n",
    "# Address the duplicates using an appropriate method. In a markdown cell, explain why you used your method of choice."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bfc96d85",
   "metadata": {},
   "source": [
    "### There are no duplicates in the dfords_clean dataframe"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a8a3db69",
   "metadata": {},
   "source": [
    "# Step 9 \n",
    "\n",
    "# Export your final, cleaned df_prods and df_ords data as “.csv” files in your “Prepared Data” folder and give them appropriate, succinct names."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "cf1137cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Exporting df_prods\n",
    "df_prods_clean_no_dups.to_csv(os.path.join(path, '02 Data','Prepared Data', 'products_checked.csv'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "69caac04",
   "metadata": {},
   "outputs": [],
   "source": [
    "dfords_clean"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "1f599094",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Exporting dfords\n",
    "dfords_clean.to_csv(os.path.join(path, '02 Data','Prepared Data', 'orders_checked.csv'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c510c73b",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
